{"training/timesteps": 344064, "training/loop": 1, "evaluation/mean_return": 265.8968200683594, "evaluation/best_return": 275.2162780761719, "evaluation/return_std": 1.0739306211471558, "losses/critic_loss": 4.926919460296631, "losses/actor_loss_mean": -22.961524963378906, "losses/alpha_loss_mean": 0.0013251856435090303, "temperature/alpha": {"_type": "histogram", "values": [2764, 1755, 2860, 2140, 2236, 1952, 2264, 5932, 4408, 4152, 5616, 3768, 2684, 1552, 2612, 5028, 1128, 1516, 1308, 1032, 1436, 920, 388, 372, 568, 328, 284, 332, 324, 332, 1568, 1977], "bins": [0.022453270852565765, 0.02323259226977825, 0.024011913686990738, 0.024791235104203224, 0.02557055652141571, 0.026349877938628197, 0.027129199355840683, 0.02790852077305317, 0.028687842190265656, 0.02946716547012329, 0.030246486887335777, 0.031025808304548264, 0.0318051278591156, 0.032584451138973236, 0.03336377069354057, 0.03414309397339821, 0.034922413527965546, 0.03570173680782318, 0.03648106008768082, 0.037260379642248154, 0.03803970292210579, 0.038819022476673126, 0.03959834575653076, 0.0403776653110981, 0.041156988590955734, 0.04193630814552307, 0.04271563142538071, 0.043494950979948044, 0.04427427425980568, 0.045053593814373016, 0.04583291709423065, 0.04661223664879799, 0.047391559928655624]}, "performance/timesteps_per_second": 5801.716552138633, "performance/loop_time": 22.59193444252014, "performance/total_time": 40.0021390914917, "training/replay_buffer_size": 344064, "training/training_steps": 131072, "_timestamp": 1754407027.0331461, "_runtime": 41.11233925819397, "_step": 5, "losses/agent_0_actor_loss": -22.977588653564453, "losses/agent_1_actor_loss": -22.94546127319336}