{"training/timesteps": 212992, "training/loop": 0, "evaluation/mean_return": 275.526611328125, "evaluation/best_return": 275.526611328125, "evaluation/return_std": 1.7266955375671387, "losses/critic_loss": 16.234153747558594, "losses/actor_loss_mean": -31.6551570892334, "losses/alpha_loss_mean": 0.2969989776611328, "temperature/alpha": {"_type": "histogram", "values": [14015, 6328, 10552, 5344, 4240, 3268, 2644, 2016, 1512, 1272, 1124, 1036, 960, 896, 840, 788, 748, 704, 672, 640, 608, 584, 556, 536, 516, 496, 480, 460, 448, 432, 416, 405], "bins": [0.04147263988852501, 0.071426622569561, 0.1013806015253067, 0.1313345730304718, 0.1612885594367981, 0.1912425458431244, 0.2211965173482895, 0.2511504888534546, 0.2811044752597809, 0.3110584616661072, 0.34101244807243347, 0.37096643447875977, 0.40092039108276367, 0.43087437748908997, 0.46082836389541626, 0.49078235030174255, 0.5207363367080688, 0.5506902933120728, 0.5806443095207214, 0.6105982661247253, 0.6405522227287292, 0.6705062389373779, 0.7004601955413818, 0.7304141521453857, 0.7603681683540344, 0.7903221249580383, 0.820276141166687, 0.8502300977706909, 0.8801840543746948, 0.9101380705833435, 0.9400920271873474, 0.9700460433959961, 1.0]}, "performance/timesteps_per_second": 4497.614889430815, "performance/loop_time": 29.142557382583618, "performance/total_time": 29.14255928993225, "training/replay_buffer_size": 212992, "training/training_steps": 65536, "_timestamp": 1754407139.0453873, "_runtime": 30.2526273727417, "_step": 3, "losses/agent_0_actor_loss": -31.674697875976562, "losses/agent_1_actor_loss": -31.6356201171875, "error": "unsupported format string passed to numpy.ndarray.__format__", "_wandb": {"runtime": 29}}