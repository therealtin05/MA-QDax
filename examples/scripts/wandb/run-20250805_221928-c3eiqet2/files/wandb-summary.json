{"training/timesteps": 344064, "training/loop": 1, "evaluation/mean_return": 261.8616638183594, "evaluation/best_return": 277.21783447265625, "evaluation/return_std": 1.6339523792266846, "losses/critic_loss": 5.975292682647705, "losses/actor_loss_mean": -28.397476196289062, "losses/alpha_loss_mean": 0.0005249731475487351, "temperature/alpha": {"_type": "histogram", "values": [2228, 940, 2652, 6640, 3368, 3592, 1896, 512, 576, 824, 1960, 5284, 3464, 4416, 820, 1756, 1804, 4184, 3496, 4935, 1464, 324, 412, 328, 320, 272, 208, 412, 2168, 1936, 908, 1437], "bins": [0.02559753693640232, 0.02628757804632187, 0.026977617293596268, 0.027667658403515816, 0.028357697650790215, 0.029047738760709763, 0.02973777800798416, 0.03042781911790371, 0.031117858365178108, 0.031807899475097656, 0.032497938722372055, 0.033187977969646454, 0.03387802094221115, 0.03456806018948555, 0.03525809943675995, 0.03594813868403435, 0.036638181656599045, 0.037328220903873444, 0.03801826015114784, 0.03870830312371254, 0.03939834237098694, 0.04008838161826134, 0.040778420865535736, 0.04146846383810043, 0.04215850308537483, 0.04284854233264923, 0.04353858157992363, 0.04422862455248833, 0.044918663799762726, 0.045608703047037125, 0.04629874229431152, 0.04698878526687622, 0.04767882451415062]}, "performance/timesteps_per_second": 5771.766936426594, "performance/loop_time": 22.709163665771484, "performance/total_time": 40.10123014450073, "training/replay_buffer_size": 344064, "training/training_steps": 131072, "_timestamp": 1754407209.3505855, "_runtime": 41.23126244544983, "_step": 5, "losses/agent_0_actor_loss": -28.398635864257812, "losses/agent_1_actor_loss": -28.396320343017578}